# mnist_neural_networks
A comparative analysis of neural network optimizers for image classification, highlighting the performance improvements achieved through hyperparameter tuning. 

I have conducted University research over the past years, particularly in mathematical modelling on published scientific data. Consequently, I am somewhat familiar with trial-and-error processes, which are important for hyperparameter tuning in the field of Data Science. The processes has exactly the same roots where the goal is to find the best possible parameter combinations to optimize model performance. Unlike academic research, machine and deep learning focus on optimizing parameters without a physical meaning, allowing for much more flexibility. 

I wanted to focus on deep learning and tensorflow and a well-understood and cleaned dataset already prepared in Tensorflow Datasets was an ideal opportunity to achieve my goal.

What I gained from this project:
1) Built and optimized neural networks using TensorFlow and Keras for image classification tasks.
2) Conducted a comparative analysis of optimization techniques (Adam and SGD), focusing on their impact on model performance and accuracy.
3) Systematically tuned hyperparameters to enhance model performance and achieve optimal results.
4) I built some useful functions to automate the process and gain precious time, demonstrating some modular programming skills.
5) I can confirm that trying to find the best possible parameter combination is a challenging part both in academic research and machine/deep learning.

***I finally achieved an average test accuracy score of 98.41% (with tuned SGD) over 10 cycles of 17 epochs each, with a standard deviation of 0.000374. The average loss was 0.06741, with a standard deviation of 0.002525!***

Thank you for your reading! 
